# Assignment 3: Defenses for Robust CNNs on CIFAR-10

**Course:** COL865 â€” Artificial Intelligence for Cybersecurity  
**Student:** Manish Patel
**Platform Used:** Kaggle (GPU T4 / A100)
**Framework:** PyTorch (torchvision + lpips + sklearn)

---

## ğŸ§  Overview

This project implements **four defense strategies** against common attacks on deep learning models trained with CIFAR-10:

| Threat Type | Defense Implemented | Output CSV/Image |
|--------------|---------------------|------------------|
| Adversarial Attack (FGSM) | Adversarial Training | `defense_adversarial.csv` |
| Training Set Poisoning | Spectral Signature Filtering | `defense_poison.csv` |
| Membership Inference | Label Smoothing + Temperature Scaling | `defense_mi.csv` |
| Model Inversion | Gradient Regularization | `defense_inversion.csv`, `inversion_defended.png` |

Each script is modular, self-contained, and can be executed independently.  
All results are saved in the `./output/` directory.

---

## âš™ï¸ Environment Setup

All code runs on **Python â‰¥ 3.9** with GPU acceleration (recommended).

### 1ï¸âƒ£ Install Dependencies

Run the following commands in your Kaggle or local terminal:

```bash
pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121
pip install lpips scikit-learn tqdm matplotlib pandas
```

### 2ï¸âƒ£ Directory Structure

```
assignment3/
â”‚
â”œâ”€â”€ utils.py
â”œâ”€â”€ train_baseline.py
â”œâ”€â”€ adv_defense.py
â”œâ”€â”€ poison_defense.py
â”œâ”€â”€ mi_inv_defense.py
|â”€â”€ plot.py
|â”€â”€ README.md
|â”€â”€ output_new/
|â”€â”€ plots/
â””â”€â”€ Report.pdf
```

The scripts automatically create:
```
/data/                â† CIFAR-10 dataset
/output/     â† CSVs + inversion image
/plots/           â† Generated result plots
```

---

## ğŸ§© Running the Code

### Option A: Run each defense separately

```bash
python train_baseline.py
python adv_defense.py
python poison_defense.py
python mi_inv_defense.py
```

### Option B: Run all sequentially

```bash
python train_baseline.py && python adv_defense.py && python poison_defense.py && python mi_inv_defense.py
```


### Option C: Generate all plots
After defenses are complete and CSVs are saved, run:
```bash
python plot.py
```

This will create six plots in the `plots/` directory.

---

## ğŸ“Š Output Summary

After execution, the `output/` folder will contain:

| File | Description |
|------|--------------|
| `train_history_baseline.csv` | Loss & accuracy per epoch for baseline training |
| `defense_adversarial.csv` | Îµ-sweep results (CleanAcc, AdvAcc, ASR, LPIPS) |
| `defense_poison.csv` | Fraction-sweep results (FilteredAcc, Removed) |
| `defense_mi.csv` | Membership inference comparison (Baseline vs Defended) |
| `defense_inversion.csv` | Gradient-regularization sweep (Lambda vs Accuracy) |
| `inversion_defended.png` | Final inversion image after defense |


## ğŸ“ˆ Example Plots (from `plot.py`)

| Plot | Description |
|------|-------------|
| **fgsm_asr.png** | Attack success rate vs Îµ |
| **fgsm_lpips.png** | LPIPS score vs Îµ |
| **fgsm_accuracy.png** | Clean vs Adversarial Accuracy vs Îµ |
| **poison_filtered_accuracy.png** | Accuracy vs fraction of filtered data |
| **mi_auc.png** | Membership inference comparison |
| **inversion_clean_accuracy.png** | Clean accuracy vs Î» (gradient regularization) |

---

## ğŸ§ª Expected Results (Latest Run)

| Defense | Key Metric | Observation |
|----------|-------------|-------------|
| FGSM Adv Training | ASR â†“ as Îµ â†‘ | Trade-off between robustness & accuracy |
| Spectral Filtering | Best at 1â€“3% removal | Balances purity and accuracy |
| Label Smoothing + Temp | AUC = 0.537 â†’ 0.669 | Better privacy, calibrated outputs |
| Gradient Regularization | Î»=0.02 best | Stable accuracy, reduced inversion clarity |

Final baseline clean accuracy: **93.59%**

---